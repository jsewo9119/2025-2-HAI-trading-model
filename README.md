# 2025-2 HAI DQN Trading Model Study

### í™˜ê²½ì„¤ì • (Required)

```sh
pip install uv
uv add -r requirements.txt
```

### ì‹¤í–‰

```sh
uv run main.py
```

### í•™ìŠµ
- training.ipynb

##### ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (Optional)

```sh
uv run -m modules.[module_name]
```


## í”„ë¡œì íŠ¸ ë³€ê²½ì‚¬í•­ ìš”ì•½ (Change Summary)

### ğŸ”¹ ì‹ ê·œ ì¶”ê°€ íŒŒì¼

#### modules/env.py
	â€¢	OpenAI Gym ìŠ¤íƒ€ì¼ì˜ TradingEnv í™˜ê²½ êµ¬í˜„
	â€¢	ë§¤ìˆ˜/ë§¤ë„/í™€ë“œ ì•¡ì…˜ ì²˜ë¦¬
	â€¢	ë¹„ìœ¨ ê¸°ë°˜ í¬ì§€ì…˜(%) ì ìš©
	â€¢	ìˆ˜ìˆ˜ë£Œ ë°˜ì˜
	â€¢	step(), reset() ë©”ì„œë“œ êµ¬í˜„
	â€¢	ë°±í…ŒìŠ¤íŠ¸ìš© run_with_agent() ì œê³µ

### ğŸ”¹ ì£¼ìš” ìˆ˜ì • íŒŒì¼

#### modules/agent.py
	â€¢	QNetwork ëª¨ë¸ êµ¬ì¡° ìˆ˜ì •
	â€¢	epsilon-greedy ì •ì±… ì¶”ê°€ (act())
	â€¢	ëª¨ë¸ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€ (save())

#### modules/trainer.py
	â€¢	ê¸°ì¡´ dataset ê¸°ë°˜ í•™ìŠµ ì œê±°
	â€¢	train_with_env()ë¡œ í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©° í•™ìŠµë˜ë„ë¡ ë³€ê²½
	â€¢	episode reward ê¸°ë¡ ê¸°ëŠ¥ ì¶”ê°€

#### training.ipynb
	â€¢	í•™ìŠµ í™˜ê²½ ë³€ê²½ ë°˜ì˜
	â€¢	epsilon schedule ì¶”ê°€
	â€¢	ìµœê·¼ 365ì¼ ì„±ëŠ¥ ë¹„êµ ì¶”ê°€

## ì‹œìŠ¤í…œ êµ¬ì¡° ë³€í™”

### Before
	â€¢	dataset ê¸°ë°˜ offline í•™ìŠµ
	â€¢	ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜ reward (lookahead leakage ìœ„í—˜)
	â€¢	ê±°ì˜ action=0(í™€ë“œ) í¸í–¥ ë°œìƒ

### After
	â€¢	í™˜ê²½ ê¸°ë°˜ RL êµ¬ì¡°ë¡œ ì „í™˜
	â€¢	episode ë‹¨ìœ„ í•™ìŠµ
	â€¢	ì‹¤ì‹œê°„ reward feedback
	â€¢	í–‰ë™ ë‹¤ì–‘ì„± í¬ê²Œ ì¦ê°€
	â€¢	ìµœê·¼ 1ë…„/ì „ì²´ ê¸°ê°„ ë°±í…ŒìŠ¤íŠ¸ ê°€ëŠ¥